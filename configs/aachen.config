[Mode]
debug = False

[Glidein]
site = aachen
address = http://glidein-simprod.icecube.wisc.edu:11001/jsonrpc
uuid = reimann@cluster

[Cluster]
os = RHEL7
user = reimann
scheduler = LSF
cvmfs = True
group_jobs = False
mma_cmd = qstat -u rr365051
# partitions = ih, gpu, cpu
partitions = gpu, ih

[ih]
gpu_only = True
submit_command = bsub -J IceCube.PyGlidein.ih -a "gpu openmp" -R pascal -P phys3b <
running_cmd = bjobs -w | grep "IceCube.PyGlidein.ih" | grep RUN | wc -l
idle_cmd =  bjobs -w | grep "IceCube.PyGlidein.ih" | grep PEND | wc -l
limit_per_submit = 2
max_running_jobs = 2
max_idle_jobs = 2
max_total_jobs = 2
walltime_hrs = 6
whole_node = True
whole_node_cpus = 12
whole_node_disk = 100000
whole_node_gpus = 2
whole_node_memory = 5000

[cpu]
cpu_only = True
submit_command = bsub -J IceCube.PyGlidein.cpu -a openmp <
running_cmd = bjobs -w | grep "IceCube.PyGlidein.cpu" | grep RUN | wc -l
idle_cmd = bjobs -w | grep "IceCube.PyGlidein.cpu" | grep PEND | wc -l
limit_per_submit = 2
max_running_jobs = 4
max_idle_jobs = 2
max_total_jobs = 4
whole_node = False
max_cpus_per_job = 1
max_disk_per_job = 10000
max_gpus_per_job = 0
max_memory_per_job = 4000
mem_per_core = 4000

[gpu]
gpu_only = True
submit_command = bsub -J IceCube.PyGlidein.gpu -a "gpu openmp" -R pascal -P nova0001 <
running_cmd = bjobs -w | grep "IceCube.PyGlidein.gpu" | grep RUN | wc -l
idle_cmd =  bjobs -w | grep "IceCube.PyGlidein.gpu" | grep PEND | wc -l
limit_per_submit = 5
max_running_jobs = 13
max_idle_jobs = 10
max_total_jobs = 13
walltime_hrs = 6
whole_node = True
whole_node_cpus = 8
whole_node_disk = 100000
whole_node_gpus = 2
whole_node_memory = 20000

[SubmitFile]
filename = submit.lsf
local_dir = /work/ac_icecube/IceProd/scratch/${LSB_JOBID}_${LSB_JOBINDEX}
mem_scale = 0.001
custom_middle = module load cuda
    export TEST_CUDA=$(echo $PATH | grep "cuda" | wc -l )
    if [ $TEST_CUDA = 1 ]; then CUDA_VISIBLE_DEVICES=0,1; fi
custom_end = rm -rf $LOCAL_DIR
